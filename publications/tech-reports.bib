@techreport{amos2016openface,
  title={OpenFace: A general-purpose face recognition
    library with mobile applications},
  author={Amos, Brandon and Bartosz Ludwiczuk and Satyanarayanan, Mahadev},
  _venue={CMU},
  year={2016},
  institution={Technical Report CMU-CS-16-118, CMU School of Computer Science},
  url={http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf},
  codeurl={https://cmusatyalab.github.io/openface},
  abstract={
    Cameras are becoming ubiquitous in the Internet of Things (IoT) and
    can use face recognition technology to improve context. There is a
    large accuracy gap between today's publicly available face recognition
    systems and the state-of-the-art private face recognition
    systems. This paper presents our OpenFace face recognition library
    that bridges this accuracy gap. We show that OpenFace provides
    near-human accuracy on the LFW benchmark and present a new
    classification benchmark for mobile scenarios. This paper is intended
    for non-experts interested in using OpenFace and provides a light
    introduction to the deep neural network techniques we use.

    We released OpenFace in October 2015 as an open source library under
    the Apache 2.0 license. It is available at:
    <http://cmusatyalab.github.io/openface/>
  }
}

@techreport{gao2015cloudlets,
  title={Are Cloudlets Necessary?},
  author={
    Gao, Ying and Hu, Wenlu and Ha, Kiryong and
    Amos, Brandon and Pillai, Padmanabhan and
    Satyanarayanan, Mahadev
  },
  _venue={CMU},
  year={2015},
  institution={Technical Report CMU-CS-15-139, CMU School of Computer Science},
  url={http://reports-archive.adm.cs.cmu.edu/anon/anon/2015/CMU-CS-15-139.pdf},
  abstract={
    We present experimental results from Wi-Fi and 4G LTE networks to validate the
    intuition that low end-to-end latency of cloud services improves application
    response time and reduces energy consumption on mobile devices. We focus
    specifically on computational offloading as a cloud service. Using a wide
    range of applications, and exploring both pre-partitioned and dynamically
    partitioned approaches, we demonstrate the importance of low latency for
    cloud offload services. We show the best performance is achieved by
    offloading to cloudlets, which are small-scale edge-located data centers. Our
    results show that cloudlets can improve response times 51\% and reduce energy
    consumption in a mobile device by up to 42\% compared to cloud offload.
  }
}

@techreport{ha2015adaptive,
  title={Adaptive VM handoff across cloudlets},
  author={
    Ha, Kiryong and Abe, Yoshihisa and Chen, Zhuo and
    Hu, Wenlu and Amos, Brandon and Pillai, Padmanabhan and
    Satyanarayanan, Mahadev
  },
  _venue={CMU},
  year={2015},
  institution={Technical Report CMU-CS-15-113, CMU School of Computer Science},
  url={http://ra.adm.cs.cmu.edu/anon/2015/CMU-CS-15-113.pdf},
  abstract={
    Cloudlet offload is a valuable technique for ensuring low end-to-end latency of
    resource-intensive cloud processing for many emerging mobile applications.
    This paper examines the impact of user mobility on cloudlet offload, and
    shows that even modest user mobility can result in significant network
    degradation. We propose VM handoff as a technique for seamlessly transferring
    VMencapsulated execution to a more optimal offload site as users move. Our
    approach can perform handoff in roughly a minute even over limited WANs by
    adaptively reducing data transferred. We present experimental results to
    validate our implementation and to demonstrate effectiveness of adaptation to
    changing network conditions and processing capacity
  }
}

@article{amos2014QNSTOP,
  title={{{QNSTOP-QuasiNewton Algorithm for Stochastic Optimization}}},
  author={Brandon Amos and David Easterling and Layne Watson and
    William Thacker and Brent Castle and Michael Trosset},
  journal={},
  _venue={VT},
  year={2014},
  keywords={journal},
  url={https://vtechworks.lib.vt.edu/bitstream/handle/10919/49672/qnTOMS14.pdf},
  abstract={
    QNSTOP consists of serial and parallel (OpenMP) Fortran 2003 codes for the
    quasi-Newton stochastic optimization method of Castle and Trosset. For
    stochastic problems, convergence theory exists for the particular
    algorithmic choices and parameter values used in QNSTOP. Both the parallel
    driver subroutine, which offers several parallel decomposition strategies,
    and the serial driver subroutine can be used for stochastic optimization or
    deterministic global optimization, based on an input switch. QNSTOP is
    particularly effective for “noisy” deterministic problems, using only
    objective function values. Some performance data for computational systems
    biology problems is given.
  }
}
